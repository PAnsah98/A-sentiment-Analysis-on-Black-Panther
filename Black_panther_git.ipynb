{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c755aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "api_key = 'XXXXXXXXXXXXXXXXXXXXXXX'\n",
    "api_key_secret = 'XXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the authentication object\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "\n",
    "#set the accesstoken and accesstokensecret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#create the API object while passing in the auth information\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True) #sleeps when API limit is reached\n",
    "sleep_on_rate_limit=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c71a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords and hashtags to look out for\n",
    "keywords = \"#BlackPanther2 OR #WakandaForever OR #BlackPanther\"\n",
    "search_query = keywords + \" -filter:retweets AND -filter:replies\" #filters out retweets and replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to get the tweets and append it to data\n",
    "data = []\n",
    "\n",
    "def get_tweets(search_query, limit):\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=search_query, count = 100, lang = 'en', tweet_mode= 'extended').items(limit)\n",
    "    for tweet in tweets:\n",
    "        data.append([tweet.id, #every tweet has a unique id, so get the tweet id, we will use it to check for duplicates\n",
    "        tweet.user.screen_name, #to get the username of the \"tweeter\"\n",
    "        tweet.full_text,        #to get the tweet\n",
    "        tweet.favorite_count,   #to get the number of likes on the tweet\n",
    "        tweet.retweet_count,    #the number of retweets on the tweet\n",
    "        tweet.user.location,    #to get the location of the user\n",
    "        tweet.created_at])      #date and time of tweet\n",
    "        #print(tweet)\n",
    "        \n",
    "#  Pass in search query and the number of tweets to retrieve\n",
    "get_tweets(search_query, 100000)  \n",
    "\n",
    "#Assign names to each column and print the df\n",
    "df1 = pd.DataFrame(data, columns = ['Id','Username', 'Tweet', 'No. of Likes', 'No. of Retweets', 'Location', 'Date'])\n",
    "print(df1.tail())  #print the tail of the df to get the id of the last tweet, we will use the last id to get older tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get older tweets with max_id\n",
    "data = []\n",
    "\n",
    "def get_tweets2(search_query, limit):\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=search_query,max_id = XXXXXXXXXX, count = 100, lang = 'en', tweet_mode= 'extended').items(limit)\n",
    "    for tweet in tweets:\n",
    "        data.append([tweet.id,\n",
    "        tweet.user.screen_name,\n",
    "        tweet.full_text,\n",
    "        tweet.favorite_count, \n",
    "        tweet.retweet_count,\n",
    "        tweet.user.location,\n",
    "        tweet.created_at])\n",
    "        #print(tweet)\n",
    "        \n",
    "#  Pass in search query and the number of tweets to retrieve\n",
    "get_tweets2(search_query, 50000)  \n",
    "\n",
    "#Assign names to each column and print the df\n",
    "df2 = pd.DataFrame(data, columns = ['Id','Username', 'Tweet', 'No. of Likes', 'No. of Retweets', 'Location', 'Date'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the dataframes with concat\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff17ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract hashtags and remove # with re\n",
    "def getHashtags(tweet):\n",
    "    tweet = tweet.lower()  #to reduce the tweets to lowercase\n",
    "    tweet = re.findall(r'\\#\\w+',tweet) #find all words with # at the start, ie; hashtags\n",
    "    return \" \".join(tweet)\n",
    "\n",
    "#apply the function to the Tweet column to extract the hashtags\n",
    "df['Hashtags'] = df['Tweet'].apply(getHashtags)\n",
    "df.head()\n",
    "\n",
    "hashtags_list = df['Hashtags'].tolist() #to convert the data elements into a list\n",
    "\n",
    "# Iterate over all hashtags and split where there is more than one hashtag\n",
    "hashtags = []\n",
    "for item in hashtags_list:\n",
    "    item = item.split()\n",
    "    for i in item:\n",
    "        hashtags.append(i)\n",
    "\n",
    "# Determine count of all hashtags used\n",
    "counts = Counter(hashtags)\n",
    "hashtags_df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
    "hashtags_df.columns = ['Hashtags', 'Count']\n",
    "hashtags_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "\n",
    "#print hashtags_df\n",
    "hashtags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wakanda_cast = [\"Shuri\",\"Nakia\",\"Okoye\",\"M'baku\",\"Ayo\",\"Ironheart\",\"Aneka\",\"Namor\",\"Everet\",\"T'Challa\",\"Ramonda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created a group for the first names of the cast and their respective character names. Noticed that surnames aren't there? It'd to avoid duplicates\n",
    "Wakanda_cast = \"Chadwick|Tenoch|Letitia|Lupita|Angela|Winston|Mbaku|Shuri|Nakia|Okoye|Danai|M'baku|Ayo|Ironheart|Aneka|Namor|Everet|T'Challa|Ramonda|Namora|W'Kabi|Wkabi|Mabel|Princess|Queen\"\n",
    "# Define function to extract casts from each Tweet\n",
    "def getCast(tweet):\n",
    "    tweet = tweet.lower()  \n",
    "    tweet = re.findall(Wakanda_cast, tweet, flags=re.IGNORECASE)\n",
    "    return \" \".join(tweet)\n",
    "\n",
    "#Extract casts to a new column\n",
    "df['Movie_cast'] = df['Tweet'].apply(getCast)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be31d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to replace their actual names with the character names\n",
    "def castNames(wakanda_cast):\n",
    "    replacements = [(\"Letitia\", \"shuri\"),\n",
    "                    (\"Princess\", \"shuri\"),\n",
    "                    (\"Lupita\", \"nakia\"),\n",
    "                    (\"Danai\", \"okoye\"),\n",
    "                    (\"Winston\", \"m'baku\"),\n",
    "                    (\"Mbaku\", \"m'baku\"),\n",
    "                    (\"Florence\", \"ayo\"), \n",
    "                    (\"Dominique\", \"ironheart\"), \n",
    "                    (\"Michaela\", \"aneka\"),\n",
    "                    (\"Mabel\", \"namora\"),\n",
    "                    (\"Tenoch\", \"namor\"), \n",
    "                    (\"Daniel\", \"w'kabi\"),\n",
    "                    (\"Wkabi\", \"w'kabi\"),\n",
    "                    (\"Martin\", \"everet\"), \n",
    "                    (\"Chadwick\", \"t'challa\"), \n",
    "                    (\"Angela\", \"ramonda\"),\n",
    "                    (\"Queen\", \"ramonda\")]\n",
    "    for act,rep in replacements:\n",
    "        wakanda_cast = re.sub(act, rep, wakanda_cast, flags=re.IGNORECASE)\n",
    "    return wakanda_cast\n",
    "\n",
    "df['Movie_cast'] = df['Movie_cast'].apply(castNames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e089b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the df to a list\n",
    "cast_list = df['Movie_cast'].tolist()\n",
    "\n",
    "# Iterate over all cast names and split where there is more than one cast\n",
    "cast = []\n",
    "for item in cast_list:\n",
    "    item = item.split()\n",
    "    for i in item:\n",
    "        cast.append(i)\n",
    "\n",
    "# Determine count of all cast\n",
    "counts = Counter(cast)\n",
    "cast_df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
    "cast_df.columns = ['Cast', 'Count']\n",
    "cast_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "\n",
    "cast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to clean the tweets, ie; get rid of @, RT, numbers, url and so on\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) #to remove @ mentions, + means 1 or more\n",
    "    text = re.sub(r'[#:_\\!/]', '', text) #to remove symbols\n",
    "    text = re.sub(r'RT[\\s]+', '', text) #to remove RT mentions. [\\s] means 1 or more white spaces\n",
    "    text = re.sub(r'https?:\\/\\/\\+S', '', text) #remove hyperlinks. s? means may or may not have an s. +S = may have whitespaces \n",
    "    text = re.sub(r'httpst', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#apply function to the Tweet column\n",
    "df['Tweet'] = df['Tweet'].apply(cleanTxt)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c29416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing locations with \"Unspecified\"\n",
    "df[\"Location\"]=df[\"Location\"].fillna('Unspecified')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84549d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to check if the missing locations have been replaced\n",
    "df['Location'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b43ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "df.duplicated(subset='Id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates in the dataframe\n",
    "df.drop_duplicates(subset = 'Id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93698a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary column(s). Here, I'm dropping id, since I have confirmed there are no duplicates\n",
    "df = df.drop(['Id'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Sentiments Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#Create two new columns\n",
    "df['Subjectivity'] = df['Tweet'].apply(getSubjectivity)\n",
    "df['Polarity'] = df['Tweet'].apply(getPolarity)\n",
    "\n",
    "#Show the new dataframe with the new columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to compute the polarity(negative, neutral, positive) sentiments\n",
    "def getSentiments(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "#create a new column to save the sentiments\n",
    "df['Sentiments'] = df['Polarity'].apply(getSentiments)\n",
    "\n",
    "#Show the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffa634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the wordcloud\n",
    "mask = np.array(Image.open(\"Images/wakanda.png\"))\n",
    "\n",
    "#Instantiate the wordcloud using\n",
    "allwords = ' '.join(df['Tweet'])\n",
    "wordcloud = WordCloud(\n",
    "    stopwords=STOPWORDS,\n",
    "    background_color=\"black\",\n",
    "    height = 2000,\n",
    "    width = 3000,\n",
    "    mask = mask,\n",
    "    colormap = 'Blues',\n",
    "    collocations = False,\n",
    "    max_font_size = 200).generate(allwords)\n",
    "\n",
    "# create wakanda forever image\n",
    "plt.figure(figsize=[15,10], facecolor='none')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title('Word Cloud for Black Panther 2')\n",
    "plt.savefig(\"blackpanther.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the dataframes\n",
    "df.to_csv('Black_Panther.csv')\n",
    "\n",
    "cast_df.to_csv('cast_df.csv')\n",
    "\n",
    "hashtags_df.to_csv('hashtags_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Data Visualization\n",
    "#I imported the files into power bi for the visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
